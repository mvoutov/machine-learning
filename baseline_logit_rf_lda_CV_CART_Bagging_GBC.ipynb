{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8951d5f5",
   "metadata": {
    "id": "8951d5f5"
   },
   "source": [
    "# Baseline, LOGIT, Random Forest, LDA, Cross-Validation CART, Bagging, GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80e3964a",
   "metadata": {
    "code_folding": [],
    "id": "80e3964a"
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1267ae20",
   "metadata": {
    "code_folding": [],
    "id": "1267ae20"
   },
   "outputs": [],
   "source": [
    "# Load in data\n",
    "training_data = pd.read_csv(\"data/Letters_train.csv\")\n",
    "testing_data = pd.read_csv(\"data/Letters_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6a9df",
   "metadata": {
    "id": "86d6a9df"
   },
   "source": [
    "# Question 2 (25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "73e377b6",
   "metadata": {
    "code_folding": [],
    "id": "73e377b6"
   },
   "outputs": [],
   "source": [
    "#Create new variable here\n",
    "training_data['isB'] = np.where(training_data['letter']  == 'B', 1, 0)\n",
    "testing_data['isB'] = np.where(testing_data['letter'] == 'B', 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "039a5cd0",
   "metadata": {
    "code_folding": [],
    "id": "039a5cd0"
   },
   "outputs": [],
   "source": [
    "#Split into X and y\n",
    "y = training_data['isB']\n",
    "X = training_data.drop(['letter', 'isB'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2e726",
   "metadata": {
    "id": "a7c2e726"
   },
   "source": [
    "### Part A: Baseline Model (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a5a6931e",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "a5a6931e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "# Q1A code\n",
    "most_common_label = training_data['isB'].mode()[0]\n",
    "\n",
    "baseline_predictions = [most_common_label] * len(testing_data)\n",
    "\n",
    "baseline_accuracy = accuracy_score(testing_data['isB'], baseline_predictions)\n",
    "\n",
    "baseline_1_acc = baseline_accuracy\n",
    "print(f'Baseline Test Accuracy: {baseline_1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f7dca",
   "metadata": {
    "id": "eb0f7dca"
   },
   "source": [
    "### Part B: Logistic Regression (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7fba5965",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "7fba5965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "# Q1B code\n",
    "X_train = training_data.drop(['Unnamed: 0','letter', 'isB'], axis=1)\n",
    "y_train = training_data['isB']\n",
    "\n",
    "X_test = testing_data.drop(['Unnamed: 0','letter', 'isB'], axis=1)\n",
    "y_test = testing_data['isB']\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=2023, max_iter=1500)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "model_1b_acc = accuracy_score(y_test, predictions)\n",
    "print(f'Logistic Regression Test Accuracy: {model_1b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495157d",
   "metadata": {
    "id": "7495157d"
   },
   "source": [
    "### Part C: AUC (2 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "94594df9",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "94594df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test AUC: 0.9785\n"
     ]
    }
   ],
   "source": [
    "# Q1C code\n",
    "probabilities = logistic_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "model_1b_auc =roc_auc_score(y_test, probabilities)\n",
    "print(f'Logistic Regression Test AUC: {model_1b_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75df07",
   "metadata": {
    "id": "ba75df07"
   },
   "source": [
    "### Part D: Cross-validated CART (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6132e51",
   "metadata": {
    "id": "a6132e51"
   },
   "source": [
    "**Written Answer**: \n",
    "\n",
    "* Cross-Validation for `ccp_alpha`: I used `GridSearchCV` from `sklearn.model_selection` to perform cross-validation. I defined a range of `ccp_alpha` values (between 0.0001 and 0.1) and performed cross-validation for each of them to determine the one that results in the best cross-validated metric (accuracy). I used `.best_param_` to determine the value and plugged it in the `DecisionTreeClassifier`\n",
    "\n",
    "* Train the CART model: After determining the best `ccp_alpha`, train the `DecisionTreeClassifier` from sklearn.tree with this hyperparameter on the full training set.\n",
    "\n",
    "* Evaluate the model: Make predictions on the test set and calculate the accuracy of the CART model using the `accuracy_score` function.\n",
    "\n",
    "**The best ccp_alpha is 0.0011 and the CV CART test accuracy is 94.01%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dee59e95",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "dee59e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV CART Test Accuracy: 0.9401\n",
      "Best ccp_alpha: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Q1D Code\n",
    "\n",
    "# Initialize the CART model\n",
    "cart_model = DecisionTreeClassifier(random_state=2023)\n",
    "\n",
    "# Define a range of ccp_alpha values for cross-validation\n",
    "ccp_alpha_range = np.linspace(0.0001, 0.01, 100)\n",
    "\n",
    "# Setup the grid to be searched over\n",
    "param_grid = {'ccp_alpha': ccp_alpha_range}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = KFold(n_splits=5,random_state=2023,shuffle=True) \n",
    "\n",
    "cv_cart_model = GridSearchCV(cart_model, param_grid, cv=cv, scoring='accuracy')\n",
    "cv_cart_model.fit(X_train, y_train)\n",
    "\n",
    "# Best ccp_alpha value\n",
    "model_1d_best_ccp_alpha = cv_cart_model.best_params_['ccp_alpha']\n",
    "\n",
    "# Train the CART model with the best ccp_alpha\n",
    "cart_model = DecisionTreeClassifier(random_state=2023, ccp_alpha=model_1d_best_ccp_alpha)\n",
    "cart_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "cart_predictions = cart_model.predict(X_test)\n",
    "\n",
    "model_1d_acc = accuracy_score(y_test, cart_predictions)\n",
    "\n",
    "\n",
    "print(f'CV CART Test Accuracy: {model_1d_acc:.4f}')\n",
    "print(f'Best ccp_alpha: {model_1d_best_ccp_alpha:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65edd8a",
   "metadata": {
    "id": "f65edd8a"
   },
   "source": [
    "### Part E: Random Forest (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28f7acb2",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "28f7acb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "# Q1E Code\n",
    "rf = RandomForestClassifier(random_state=2023)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf.predict(X_test)\n",
    "\n",
    "model_1e_acc = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Test Accuracy: {model_1e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648a60",
   "metadata": {
    "id": "53648a60"
   },
   "source": [
    "### Part F: Performance Comparison (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bfd25",
   "metadata": {
    "id": "e74bfd25"
   },
   "source": [
    "**Written Answer**:\n",
    "\n",
    "The Baseline model performs the worst of all, which makes it not a good model compared to the others. Logistic regression and CART models are equivalent in performance at 94%. Whereas Random forest model's performance is much better at 98.4%. Logistic regression and CART models are more interpretable. Logistic regression provides coefficients that tell you the effect size of each feature, and CART provides a decision tree that can be visualized and understood even by non-experts. Random Forest is usually more accurate than CART and logistic regression because it builds multiple trees and averages their predictions, which can capture more complex patterns in the data.\n",
    "\n",
    "The importance between accuracy and interpretibility depends each situation and highly depends who is the intended reader. in the current problem, given that it is letter recognition, accuracy might be more important since the model might be used to sort mail, therefore accuracy is more important than interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0015fa9c",
   "metadata": {
    "code_folding": [],
    "id": "0015fa9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Test Accuracy\n",
      "0             Baseline       0.774332\n",
      "1  Logistic Regression       0.940107\n",
      "2                 CART       0.940107\n",
      "3        Random Forest       0.983957\n"
     ]
    }
   ],
   "source": [
    "# Q1F Code\n",
    "accuracies = {\n",
    "    'Model': ['Baseline','Logistic Regression', 'CART', 'Random Forest'],\n",
    "    'Test Accuracy': [baseline_1_acc, model_1b_acc, model_1d_acc, model_1e_acc]\n",
    "}\n",
    "accuracy_df = pd.DataFrame(accuracies)\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4307762",
   "metadata": {
    "id": "e4307762"
   },
   "source": [
    "***\n",
    "# Question 3 (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0dd917ee",
   "metadata": {
    "code_folding": [],
    "id": "0dd917ee"
   },
   "outputs": [],
   "source": [
    "#Redefine target y\n",
    "y_train_multiclass = training_data['letter']\n",
    "y_test_multiclass = testing_data['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2553f29",
   "metadata": {
    "id": "e2553f29"
   },
   "source": [
    "### Part A: Baseline Model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d84b11f",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "3d84b11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.2439\n"
     ]
    }
   ],
   "source": [
    "# Q2A\n",
    "most_common_class = y_train_multiclass.mode()[0]\n",
    "\n",
    "baseline_predictions_multiclass = [most_common_class] * len(y_test_multiclass)\n",
    "\n",
    "baseline_2_acc = accuracy_score(y_test_multiclass, baseline_predictions_multiclass)\n",
    "print(f'Baseline Test Accuracy: {baseline_2_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f682d",
   "metadata": {
    "id": "555f682d"
   },
   "source": [
    "### Part B: LDA (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8860299d",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "8860299d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test Accuracy: 0.9102\n"
     ]
    }
   ],
   "source": [
    "# Q2B code\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_model.fit(X_train, y_train_multiclass)\n",
    "\n",
    "lda_predictions = lda_model.predict(X_test)\n",
    "\n",
    "model_2b_acc =  accuracy_score(y_test_multiclass, lda_predictions)\n",
    "print(f'LDA Test Accuracy: {model_2b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75cc6e",
   "metadata": {
    "id": "3c75cc6e"
   },
   "source": [
    "### Part C: Cross-validated CART (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfa50d",
   "metadata": {
    "id": "21dfa50d"
   },
   "source": [
    "**Written Answer**:\n",
    "\n",
    "The best ccp_alpha value from CV for the CART model is approximately 0.0006. The highest cross-validated accuracy achieved with this ccp_alpha is around 91.94%.\n",
    "\n",
    "\n",
    "* Cross-Validation for `ccp_alpha`: I used `cross_val_score` from `sklearn.model_selection` to perform cross-validation. I defined a range of `ccp_alpha` values (between 0.0001 and 0.1) and performed cross-validation for each of them to determine the one that results in the best cross-validated metric (accuracy). I used `.best_param_` to determine the value and plugged it in the `DecisionTreeClassifier`\n",
    "\n",
    "* Train the CART model: After determining the best `ccp_alpha`, train the `DecisionTreeClassifier` from sklearn.tree with this hyperparameter on the full training set.\n",
    "\n",
    "* Evaluate the model: Make predictions on the test set and calculate the accuracy of the CART model using the `accuracy_score` function.\n",
    "\n",
    "**The best ccp_alpha is 0.0011 and the CV CART test accuracy is 94.01%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "80208cc3",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "80208cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Test Accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "# Q2C Code\n",
    "cart_model_multiclass = DecisionTreeClassifier(random_state=2023)\n",
    "\n",
    "# Define a range of ccp_alpha values\n",
    "ccp_alpha_range_multiclass = np.linspace(0.0001, 0.01, 100)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = [cross_val_score(DecisionTreeClassifier(random_state=2023, ccp_alpha=alpha),\n",
    "                             X_train, y_train_multiclass, cv=5, scoring='accuracy').mean() \n",
    "             for alpha in ccp_alpha_range_multiclass]\n",
    "\n",
    "# Find the best ccp_alpha value\n",
    "best_index = np.argmax(cv_scores)\n",
    "best_ccp_alpha_multiclass = ccp_alpha_range_multiclass[best_index]\n",
    "best_cv_score = cv_scores[best_index]\n",
    "\n",
    "# Train the CART model with the best ccp_alpha\n",
    "cart_model_multiclass = DecisionTreeClassifier(random_state=2023, ccp_alpha=best_ccp_alpha_multiclass)\n",
    "cart_model_multiclass.fit(X_train, y_train_multiclass)\n",
    "\n",
    "# Make predictions on the test set\n",
    "cart_predictions_multiclass = cart_model_multiclass.predict(X_test)\n",
    "\n",
    "model_2c_acc = accuracy_score(y_test_multiclass, cart_predictions_multiclass)\n",
    "print(f'CART Test Accuracy: {model_2c_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31acb6",
   "metadata": {
    "id": "1a31acb6"
   },
   "source": [
    "### Part D: Vanilla Bagging (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ce7d3724",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "ce7d3724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CV Random Forest Test Accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Q2D\n",
    "# Find the total number of features\n",
    "total_features = X_train.shape[1]\n",
    "\n",
    "# Initialize the RF model with m=p \n",
    "bagging_model = RandomForestClassifier(max_features=total_features, random_state=2023)\n",
    "\n",
    "# Train the model \n",
    "bagging_model.fit(X_train, y_train_multiclass)\n",
    "\n",
    "# Make predictions on test\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of RF model\n",
    "model_2d_acc = accuracy_score(y_test_multiclass, bagging_predictions)\n",
    "print(f'No CV Random Forest Test Accuracy: {model_2d_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d3365",
   "metadata": {
    "id": "903d3365"
   },
   "source": [
    "### Part E: Cross-validated Random Forest (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad086a5",
   "metadata": {
    "id": "0ad086a5"
   },
   "source": [
    "**Written Answer**: \n",
    "\n",
    "* Parameter Grid Setup: I define a parameter grid for `max_features` ranging from 1 to the total number of features present in the data.\n",
    "\n",
    "* Grid Search with Cross-Validation: For the RF model, I used GridSearchCV, 5-fold cross-validation, with scoring parameter of 'accuracy'.\n",
    "\n",
    "* Performing Grid Search: I call `grid_search.fit()` on the training data (`X_train, y_train_multiclass`), to do cross-validation for each possible value of `max_features`.\n",
    "\n",
    "* Selecting the Best `max_features`: Retreive optimal `max_features` from `grid_search.best_params_`. This value is the one that, on average, produces the highest cross-validated accuracy score.\n",
    "\n",
    "* Training the Final Model: Train a new RF model on the whole training set using the best `max_features` value.\n",
    "\n",
    "* Testing the Model: using the best RF model (from train) to predict the classes on the test set (X_test), and use the `accuracy_score` function to compare the predictions (`rf_predictions`) against the actual values (`y_test_multiclass`) to calculate the test set accuracy.\n",
    "The test set accuracy for the Random Forest model after cross-validation is 97.65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f2bae54c",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f2bae54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Random Forest Test Accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "# Q2E\n",
    "# Set up the param grid for max_features\n",
    "param_grid = {'max_features': range(1, total_features + 1)}\n",
    "\n",
    "# Initialize the RF model\n",
    "rf_grid_search = RandomForestClassifier(random_state=2023)\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_grid_search, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train_multiclass)\n",
    "\n",
    "# Get the best max_features value\n",
    "best_max_features = grid_search.best_params_['max_features']\n",
    "\n",
    "# Train a model with the best max_features value\n",
    "best_rf_model = RandomForestClassifier(max_features=best_max_features, random_state=2023)\n",
    "best_rf_model.fit(X_train, y_train_multiclass)\n",
    "\n",
    "# Make predictions on test set with the best model\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "model_2e_acc = accuracy_score(y_test_multiclass, rf_predictions)\n",
    "print(f'CV Random Forest Test Accuracy: {model_2e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969e7f2",
   "metadata": {
    "id": "1969e7f2"
   },
   "source": [
    "### Part F: Gradient Boosting Classifier (9 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f9bd4e72",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f9bd4e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Test Accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# Q2F\n",
    "# Initialize the GBC\n",
    "gbc_model = GradientBoostingClassifier(n_estimators=200, max_leaf_nodes=10, random_state=2023)\n",
    "\n",
    "# Train the model\n",
    "gbc_model.fit(X_train, y_train_multiclass)\n",
    "\n",
    "# Make predictions\n",
    "gbc_predictions = gbc_model.predict(X_test)\n",
    "\n",
    "model_2f_acc = accuracy_score(y_test_multiclass, gbc_predictions)\n",
    "print(f'GBC Test Accuracy: {model_2f_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a29e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!jupyter nbconvert --to html ieor_142_hw4_starter_code.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
